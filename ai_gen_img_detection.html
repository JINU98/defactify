<!DOCTYPE html>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
  <head>
    <title>CT2 : AI-Generated Image Detection</title>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, user-scalable=no"
    />
    <!-- Open Graph Meta Tags for AI-Generated Image Detection Shared Task -->
    <meta property="og:title" content="Participate in AI-Generated Image Detection - Defactify 4.0 Workshop">
    <meta property="og:description" content="Get involved in the AI-Generated Image Detection shared task at Defactify 4.0 Workshop and advance the field of image forensics.">
    <meta property="og:image" content="./images/preview.png">
    <meta property="og:image:width" content="120">
    <!-- <meta property="og:image:height" content="627"> -->

    <meta property="og:url" content="https://defactify.com/ai_gen_img_detection.html">

    <link rel="stylesheet" href="assets/css/main.css" />
    <link rel="icon" href="./images/favicon.ico" type="image/x-icon">

    <!-- Link to external CSS file -->
    <link rel="stylesheet" href="style.css" />
  </head>

  <body class="is-preload">
    <!-- Wrapper -->
    <div id="wrapper">
      <!-- Main -->
      <div id="main">
        <div class="inner">
          <!-- Header -->
          <header id="header"></header>


          <!-- Content -->
          <section>
            <div style="background: url('https://aiisc.ai/defactify/img/background.gif');">
                <header class="main" style="text-align: center;">
                    <span class="logo_image main" ><img src="./images/img_detect_shared_task_banner.png" alt="" /></span>

                    <div>
                        <h1 class="heading_bannerh1" style="color: #fff;"><a href="https://aaai.org/aaai-conference/" target="_blank"
										rel="noopener noreferrer">@ AAAI 2025</a> </h1>
								<h2 class="heading_bannerh2" style="color: #fff;">Fourth Workshop on ​Multimodal Fact Checking and Hate Speech
									Detection <br>
									February, 2025</h2>
                    </div>

                </header>
            </div>

            <!-- <p>Donec eget ex magna. Interdum et malesuada fames ac ante ipsum primis in faucibus. Pellentesque venenatis dolor imperdiet dolor mattis sagittis. Praesent rutrum sem diam, vitae egestas enim auctor sit amet. Pellentesque leo mauris, consectetur id ipsum sit amet, fergiat. Pellentesque in mi eu massa lacinia malesuada et a elit. Donec urna ex, lacinia in purus ac, pretium pulvinar mauris. Curabitur sapien risus, commodo eget turpis at, elementum convallis elit. Pellentesque enim turpis, hendrerit.</p>
									<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis dapibus rutrum facilisis. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Etiam tristique libero eu nibh porttitor fermentum. Nullam venenatis erat id vehicula viverra. Nunc ultrices eros ut ultricies condimentum. Mauris risus lacus, blandit sit amet venenatis non, bibendum vitae dolor. Nunc lorem mauris, fringilla in aliquam at, euismod in lectus. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. In non lorem sit amet elit placerat maximus. Pellentesque aliquam maximus risus, vel sed vehicula.</p>
									<p>Interdum et malesuada fames ac ante ipsum primis in faucibus. Pellentesque venenatis dolor imperdiet dolor mattis sagittis. Praesent rutrum sem diam, vitae egestas enim auctor sit amet. Pellentesque leo mauris, consectetur id ipsum sit amet, fersapien risus, commodo eget turpis at, elementum convallis elit. Pellentesque enim turpis, hendrerit tristique lorem ipsum dolor.</p> -->

            <hr class="major" />
            <header class="major" id="about">
              <h2> About : CT<sup>2</sup> - AI Generated Image Detection</h2>
            </header>

                  
            <h4>Important News Datasets Released:</h4>
            <h4>CT<sup>2</sup> - AI Generated Image Detection</h4>
            <span>Colab: </span><a href="https://codalab.lisn.upsaclay.fr/competitions/20331" target="_blank" rel="noopener noreferrer">https://codalab.lisn.upsaclay.fr/competitions/20331</a>
            <br>
            <span>Form:</span><a href="https://forms.gle/nmKYsCYY2odZGP4x9" target="_blank">https://forms.gle/nmKYsCYY2odZGP4x9</a>
            <br>
            <br>
            <br>

            <h4 class="dataset_heading"><a href="https://huggingface.co/datasets/NasrinImp/Defactify4_Train" target="_blank">Dataset:</a></h4>
            <p>
              Several text-to-image generation systems are available today. To
              determine which types of model-generated images are easier or
              harder to detect, we will include a diverse range of models, such
              as Stable Diffusion 3 (SD 3), Stable Diffusion XL (SDXL), Stable
              Diffusion 2.1 (SD 2.1), DALL-E 3, and Midjourney 6. We will
              release a dataset of 50K samples for this task, developed based on
              the MS COCO dataset.
            </p>
            <p>
              The process involves taking the original MS COCO captions and
              images, feeding the captions into each of the models (SD 3, SDXL,
              SD 2.1, DALL-E 3, and Midjourney 6), and storing the generated
              images. This resulting dataset will be referred to as MS COCOAI. A
              snapshot of the data can be viewed <a href="https://huggingface.co/datasets/NasrinImp/Defactify4_Train" target="_blank">here</a>.
            </p>

            <h4>Tasks:</h4>
            <ol>
              <li>
                Task A: This is a binary classification task where the goal is
                to determine whether each given image was generated by AI or
                created by a human.
              </li>
              <li>
                Task B: Building on Task A, this task challenges participants to
                determine which specific model generated a given image.
                Participants must identify whether the images were produced by
                models such as SD 3, SDXL, SD 2.1, DALL-E 3, or Midjourney 6.
              </li>
            </ol>

            <h4>Baseline:</h4>
            <p>
              AI-generated image detection has recently garnered significant
              research attention. Proposed detection techniques can be broadly
              categorized into two paradigms: artifact-based detection and
              feature representation-based detection.
            </p>
            <p>
              For artifact-based detection, techniques include NPR, DM Image
              Detection, GAN DCT Analysis, and more. For feature
              representation-based detection, examples include CNN Detection,
              DIRE, AEROBLADE, LASTED, and others.
            </p>
            <p>
              As generative models become increasingly advanced, the need for
              sophisticated detection methods is growing. Studies have observed
              that each generative model leaves distinct traces in the frequency
              domain of the generated images, which can be considered an
              artificial fingerprint used for detection.
            </p>

            <div style="text-align: center" class="intrinsic_section">
              <img
                src="images/intrinsic_image.png"
                alt="Artificial Fingerprint Example"
                class="intrinsic_image"
              />
              				<p>
											Synthetic images generated by models like StyleGAN-T, GALIP, Taming Transformers, DALL·E Mini, Stable Diffusion, and eDiff-I (top) contain unique traces known as artificial fingerprints. These fingerprints are detectable in the frequency domain as spectral peaks in the power spectra (middle) and in the spatial domain as anomalous patterns in the auto-correlation (bottom). Similar artifacts are observed in models sharing similar architectures, enabling forensic analysis of generated content.
	
										</p>
            </div>

            <!-- <h4>Important News:</h4> -->
            <p>
              According to a report by the European Union Law Enforcement
              Agency, 90 percent of online content could be synthetically
              generated by 2026. Generative systems like DALL-E and Stable
              Diffusion are impressive but raise concerns about potential
              misuse, particularly in spreading misinformation. Some examples
              can be seen below:
            </p>

            <div class="task2_img_section">

              <div class="image-container">
                <div class="image-text">
                  <img src="./images/taylor.png" alt="Taylor Swift Image">
                  <p>A screenshot from a video showing Taylor Swift holding a flag reading "Trump Won" went viral in February 2024. The video, shared by numerous accounts on X, has reached over 4.5 million viewers. However, it is important to note that this content is AI-generated. For more details, see the <a href="https://www.forbes.com/sites/mattnovak/2024/02/05/viral-video-of-taylor-swift-endorsing-donald-trump-is-completely-fake/" target="_blank">Forbes story</a>.</p>
                </div>
                <div class="image-text">
                  <img src="./images/pope.png" alt="Pope Image">
                  <p>An AI-generated image of Pope Francis wearing a gigantic white puffer jacket went viral on social media platforms like Reddit and Twitter (X) in March of last year. This image sparked widespread media discussions about the potential misuse of Generative AI technologies, ultimately becoming an iconic example of AI-generated misinformation. For more details, see the <a href="https://www.forbes.com/sites/mattnovak/2023/03/26/that-viral-image-of-pope-francis-wearing-a-white-puffer-coat-is-totally-fake/" target="_blank">Forbes story</a>.</p>
                </div>
              </div>
              
              

            </div>
          </section>

          <section>
            <header class="major" id="important">
              <h2>IMPORTANT DATES</h2>
            </header>

            <ul>
              <li>22 October 2024 : Release of the validation set.</li>
              <li>8 November 2024 : Release of the test set.</li>
              <li>
                30 November 2024 : Deadline for submitting the final results.
              </li>
              <li>3 December 2024 : Announcement of the results.</li>
              <li>
                10 December 2024 : System paper submission deadline (All teams
                are invited to submit a paper).
              </li>
              <li>20 December 2024 : Notification of system papers.</li>
              <li>25 December 2024 : Camera ready submission.</li>
            </ul>
          </section>

          <!-- organizers -->
          <section id="organizing_committee_chairs"> </section>

          <section class="organizers" id = "web-chair"></section>
            
    
          <section class="organizers" id = "organizers"></section>
    
          <!-- <section class="organizers" id = "organizers">
            <h2>Web Chair</h2>
            <div class="card-container">
              <div class="card">
                <img src="./images/Rajarshi.jpg" alt="Rajarshi Roy" class="organizer-image">
                <h4>Rajarshi Roy</h4>
                <p>Kalyani Government Engineering College</p>
                <div class="links">
                  <a href="https://www.linkedin.com/in/rajarshi-roy-learner/" target="_blank">LinkedIn</a>
                  <a href="https://rajarshi12321.github.io/rajarshi_portfolio/" target="_blank">Portfolio</a>
                </div>
              </div>
        
            </div>
          
          </section>
           -->
          
    
        <section id = "contacts"></section>
              
          <!-- Sidebar -->
        
        <div id="sidebar"></div>
            
        <!-- Scripts -->
         
        <script src="base.js"></script>
    
        <script src="assets/js/jquery.min.js"></script>
        <script src="assets/js/browser.min.js"></script>
        <script src="assets/js/breakpoints.min.js"></script>
        <script src="assets/js/util.js"></script>
        <script src="assets/js/main.js"></script>
      </body>
    </html>