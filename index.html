<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
	<title>Defactify 4 Workshop</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<!-- Open Graph Meta Tags for Defactify 4.0 Workshop -->
	<meta property="og:title" content="Defactify 4.0 Workshop">
	<meta property="og:description" content="Join the Defactify 4.0 Workshop to explore the latest advancements in AI-generated text and image detection.">
	<meta property="og:image" content="./images/preview.png">
	<!-- <meta property="og:image:width" content="1200"> -->
    <!-- <meta property="og:image:height" content="627"> -->

	<meta property="og:url" content="https://defactify.com">

	<link rel="stylesheet" href="assets/css/main.css" />
	<link rel="icon" href="./images/favicon.ico" type="image/x-icon">

	<!-- Link to external CSS file -->
    <link rel="stylesheet" href="style.css">
</head>

<body class="is-preload">

	<!-- Wrapper -->
	<div id="wrapper">

		<!-- Main -->
		<div id="main">
			<div class="inner">

				<!-- Header -->
				<header id="header"></header>

	
				<!-- Content -->
				<section>

					<div style="background: url('https://aiisc.ai/defactify/img/background.gif'); border-radius: 2rem; padding-bottom: 2rem;">
						<header class="main" style="text-align: center;">
							<span class="logo_image main"><img src="./images/factifY_4.png"  style="width:90%;"alt="" /></span>

							<div>
								<h1 class="heading_bannerh1" style="color: #fff;"><a href="https://aaai.org/aaai-conference/" target="_blank"
										rel="noopener noreferrer">@ AAAI 2025</a> </h1>
								<h2 class="heading_bannerh2" style="color: #fff;">Fourth Workshop on ​Multimodal Fact Checking and Hate Speech
									Detection <br>
									February, 2025</h2>
							</div>

						</header>
					</div>

					<!-- <p>Donec eget ex magna. Interdum et malesuada fames ac ante ipsum primis in faucibus. Pellentesque venenatis dolor imperdiet dolor mattis sagittis. Praesent rutrum sem diam, vitae egestas enim auctor sit amet. Pellentesque leo mauris, consectetur id ipsum sit amet, fergiat. Pellentesque in mi eu massa lacinia malesuada et a elit. Donec urna ex, lacinia in purus ac, pretium pulvinar mauris. Curabitur sapien risus, commodo eget turpis at, elementum convallis elit. Pellentesque enim turpis, hendrerit.</p>
									<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis dapibus rutrum facilisis. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Etiam tristique libero eu nibh porttitor fermentum. Nullam venenatis erat id vehicula viverra. Nunc ultrices eros ut ultricies condimentum. Mauris risus lacus, blandit sit amet venenatis non, bibendum vitae dolor. Nunc lorem mauris, fringilla in aliquam at, euismod in lectus. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. In non lorem sit amet elit placerat maximus. Pellentesque aliquam maximus risus, vel sed vehicula.</p>
									<p>Interdum et malesuada fames ac ante ipsum primis in faucibus. Pellentesque venenatis dolor imperdiet dolor mattis sagittis. Praesent rutrum sem diam, vitae egestas enim auctor sit amet. Pellentesque leo mauris, consectetur id ipsum sit amet, fersapien risus, commodo eget turpis at, elementum convallis elit. Pellentesque enim turpis, hendrerit tristique lorem ipsum dolor.</p> -->

					<hr class="major" />
					<header class="major" id="about">
						<h2>ABOUT THE WORKSHOP</h2>
					</header>
					<p>
						Combating fake news is one of the pressing societal crises. It is difficult to expose false claims before they cause significant damage. Automatic fact and claim verification has recently become a topic of interest among diverse research communities. While research efforts and datasets on text-based fact verification are available, there has been limited attention towards multimodal or cross-modal fact verification. This workshop aims to encourage researchers from interdisciplinary domains working on multimodality and/or fact-checking to come together and work on multimodal (images, memes, videos) fact-checking. At the same time, multimodal hate speech detection is a critical problem but has not received sufficient attention. Lastly, learning joint modalities is of interest to both Natural Language Processing (NLP) and Computer Vision (CV) communities.
					</p>
					<p>
						Over the last decade, both fields of study—NLP and CV—have made significant progress, largely due to the success of neural networks. Multimodal tasks like visual question answering (VQA), image captioning, video captioning, and caption-based image retrieval have gained prominence in both NLP and CV forums. Multimodality is the next big leap for the AI community. De-Factify is a dedicated forum for discussing challenges related to multimodal fake news and hate speech. We also encourage discussions on multimodal tasks in general.

					</p>
					<p>
						Link to previous year's workshop : <a href="/2024/index.html" target="_blank"
							rel="noopener noreferrer">Defactify @ AAAI 2024</a>
					</p>

					<h4><a href="#shared">&#9733; Shared Tasks</a></h4>

					<ul>
						<!-- <li>
							Please register here to access the <a
								href="https://codalab.lisn.upsaclay.fr/competitions/16053" target="_blank"
								rel="noopener noreferrer">dataset.</a>
						</li>
						<li>
							Evaluation metric : The official evaluation metric for the shared task is weighted-average
							F1 score.
						</li>
						<li>
							Submission instructions : <strong>TBD</strong>
						</li> -->
						<li>
							System description paper : All teams/participants will be invited to submit a paper
							describing their system. Accepted papers will be published in formal proceedings.
						</li>
						<li>
							Paper submission instruction :<strong>TBD</strong>
						</li>
					</ul>

					<div>
						<div>
							<ol>
								<li>
									<h3> CT<sup>2</sup>: AI-Generated Text Detection</h3>
									<p>
										The widespread use of AI models like ChatGPT has sparked concerns over the proliferation of AI-generated text. Several major organizations and conferences have already banned or restricted its use. The increasing presence of AI-generated content has made it critical to develop reliable methods for detecting such text. Two main approaches have emerged: watermarking, which embeds detectable markers during generation, and post-hoc methods, which analyze and identify AI-generated content after its creation. With the growing complexity of AI systems, the need for effective detection methods has never been more urgent.
									</p>
									<p>
										A new interesting technique proposed at ICML 2024 finds that LLMs are more inclined to modify human-written text than AI-generated text when tasked with rewriting. This approach, named the geneRative AI Detection viA Rewriting method (Raidar), will be used as the baseline for the Shared Tasks.
									  </p>
						  
									  <div style="text-align: center">
										<img
										  src="./images/RAIDAR.png"
										  alt="Raidar Example"
										  style="width: 80%; height: auto; max-width: 600px;"
										/>
										<p>
										  The authors highlight character deletions in red and character insertions in orange. Their findings indicate that human-generated text generally prompts more modifications compared to machine-generated text when rewritten.
										</p>
									  
	
									<section>
								</li>
	
								<li>
									<h3> CT<sup>2</sup>: AI-Generated Image Detection</h3>
	
								
									<p>
										CT<sup>2</sup>: AI-Generated Image Detection addresses the growing challenge of identifying AI-generated images from models like DALL-E, Stable Diffusion, and Midjourney. As generative AI advances, detecting such content is vital for combating misinformation. This project provides a diverse dataset based on MS COCO, showcasing images from various models. Participants must determine whether images are AI-generated and identify the model used. Detection techniques include artifact-based and feature representation methods, enhancing accuracy in identifying AI-generated content.
									</p>
									
									<p>Recent research shows that each generative model leaves detectable traces or "fingerprints" in the frequency domain of images, which can be used for forensic analysis.</p>
									
									<div style="text-align: center" class="intrinsic_section">
										<img
										  src="images/intrinsic_image.png"
										  alt="Artificial Fingerprint Example"
										  class="intrinsic_image"
										/>
														<p>
											Synthetic images generated by models like StyleGAN-T, GALIP, Taming Transformers, DALL·E Mini, Stable Diffusion, and eDiff-I (top) contain unique traces known as artificial fingerprints. These fingerprints are detectable in the frequency domain as spectral peaks in the power spectra (middle) and in the spatial domain as anomalous patterns in the auto-correlation (bottom). Similar artifacts are observed in models sharing similar architectures, enabling forensic analysis of generated content.
	
										</p>
									  </div>
	
									  <p>
										According to a report by the European Union Law Enforcement
										Agency, 90 percent of online content could be synthetically
										generated by 2026. Generative systems like DALL-E and Stable
										Diffusion are impressive but raise concerns about potential
										misuse, particularly in spreading misinformation. Some examples
										can be seen below:
									  </p>
									
									<div class="task2_img_section">
	
										<div class="image-container">
											<div class="image-text">
												<img src="./images/taylor.png" alt="Taylor Swift Image">
												<p>A screenshot from a video showing Taylor Swift holding a flag reading "Trump Won" went viral in February 2024. The video, shared by numerous accounts on X, has reached over 4.5 million viewers. However, it is important to note that this content is AI-generated. For more details, see the <a href="https://www.forbes.com/sites/mattnovak/2024/02/05/viral-video-of-taylor-swift-endorsing-donald-trump-is-completely-fake/" target="_blank">Forbes story</a>.</p>
											</div>
											<div class="image-text">
												<img src="./images/pope.png" alt="Pope Image">
												<p>An AI-generated image of Pope Francis wearing a gigantic white puffer jacket went viral on social media platforms like Reddit and Twitter (X) in March of last year. This image sparked widespread media discussions about the potential misuse of Generative AI technologies, ultimately becoming an iconic example of AI-generated misinformation. For more details, see the <a href="https://www.forbes.com/sites/mattnovak/2023/03/26/that-viral-image-of-pope-francis-wearing-a-white-puffer-coat-is-totally-fake/" target="_blank">Forbes story</a>.</p>
											</div>
										</div>
										
										
	
									</div>
								</li>
							</ol>
	
	
						</div>
					</section>
	



					<section>
						<header class="major" id="call">
							<h2>CALL FOR SUBMISSIONS</h2>
						</header>
						<h3>REGULAR PAPER SUBMISSION</h3>
					
						<div style="text-align:center">
						</div>
					
						<h4>Topics of Interest</h4>
						<p>This forum brings attention to collecting, measuring, managing, mining, and understanding multimodal disinformation, misinformation, and malinformation data from social media. This workshop covers (but is not limited to) the following topics:</p>
						<ul>
							<li>
								Development of corpora and annotation guidelines for multimodal fact-checking.
							</li>
							<li>
								Computational models for multimodal fact-checking.
							</li>
							<li>
								Development of corpora and annotation guidelines for multimodal hate speech detection and classification.
							</li>
							<li>
								Computational models for multimodal hate speech detection and classification.
							</li>
							<li>
								Analysis of the diffusion of multimodal fake news and hate speech in social networks.
							</li>
							<li>
								Understanding the impact of hate content on specific groups (such as targeted groups).
							</li>
							<li>
								Fake news and hate speech detection in low-resource languages.
							</li>
							<li>
								Hate speech normalization.
							</li>
							<li>
								Case studies and/or surveys related to multimodal fake news or hate speech.
							</li>
							<li>
								Analyzing behavior and psychology of multimodal hate speech/fake news propagators.
							</li>
							<li>
								Real-world/applied tool development for multimodal hate speech/fake news detection.
							</li>
							<li>
								Early detection of multimodal fake news/hate speech.
							</li>
							<li>
								Use of modalities other than text and images (such as audio, video, etc.).
							</li>
							<li>
								Evolution of multimodal fake news and hate speech.
							</li>
							<li>
								Information extraction, ontology design, and knowledge graph creation for multimodal hate speech and fake news.
							</li>
							<li>
								Cross-lingual, code-mixed, and code-switched multimodal fake news/hate speech analysis.
							</li>
							<li>
								Computational social science.
							</li>
						</ul>
					
						<h4>Submission Instructions:</h4>
						<ul>
							<li><strong>Long papers: </strong> Novel, unpublished, high-quality research papers. 10 pages excluding references.</li>
							<li><strong>Short papers:</strong> 5 pages excluding references.</li>
							<li><strong>Previously rejected papers:</strong> You can attach comments from previously rejected papers (AAAI, NeurIPS) and a 1-page cover letter explaining the changes made.</li>
							<li><strong>Extended abstracts: </strong>2 pages excluding references. Non-archival, can be previously published papers or work in progress.</li>
							<li>All papers must be submitted via our EasyChair submission page.</li>
							<li>Regular papers will go through a double-blind peer-review process. Extended abstracts may be either single-blind (i.e., reviewers are blind, authors have names on submission) or double-blind (i.e., authors and reviewers are blind). Only manuscripts in PDF or Microsoft Word format will be accepted.</li>
							<li>Paper template: <a href="http://ceur-ws.org/Vol-XXX/CEURART.zip" target="_blank" rel="noopener noreferrer">http://ceur-ws.org/Vol-XXX/CEURART.zip</a> or <a href="https://www.overleaf.com/read/gwhxnqcghhdt" target="_blank" rel="noopener noreferrer">https://www.overleaf.com/read/gwhxnqcghhdt</a></li>
						</ul>
					
						<p>Paper Submission Link: <a href="https://easychair.org/conferences/?conf=defactify24" target="_blank" rel="noopener noreferrer">EasyChair</a></p>
					
						<h4>Important Dates:</h4>
						<ul>
							<li>05 January 2025: Papers due at 11:59 PM UTC-12</li>
							<li>20 January 2025: Notification of papers</li>
							<li>25 January 2025: Camera-ready submission of accepted papers due at 11:59 PM UTC-12</li>
						</ul>
					</section>
					

				<section>

					<header class="major" id="shared">
						<h2>Shared tasks</h2>
					</header>

					<!-- <ol>
									 <li> <a href="http://" target="_blank" rel="noopener noreferrer" style="font-weight: 700;"> FACTIFY</a> - Multi-Modal Fact Verification. please visit this link for details.</li>
										<li>  <a href="http://" target="_blank" rel="noopener noreferrer" style="font-weight: 700;"> MEMOTION 2</a>  - Task on analysis of memes. please visit this link for details.</li>
									</ol> -->

					<div class="features" style="text-align: center;">

						<!-- <article> -->

							<!-- <span  style="background-image: url('https://aiisc.ai/defactify/img/factify_logo_nav.png');" ></span> -->
<!-- 

							<div class="content">
								<img src="./images/factifY_4.png" style="width:120px;height: 120px;" alt="" srcset="">
								<p>Factify5WQA - Please visit <a href="./ai_gen_txt_detection.html" target="_blank"
										rel="noopener noreferrer">this link</a> for details.</p>
							</div>



						</article>
						<article>
 -->

							<!-- <div class="content">
								<img src="./images/dehate_logo.png" style="width:120px;height: 120px;" alt="" srcset="">

								<p>DE : HATE - Please visit <a href="./dehate.html" target="_blank"
										rel="noopener noreferrer">this link</a> for details.</p>
							</div> -->


						<!-- </article> -->
						<!-- TODO : ADD REFLINKS TO WEBPAGES. -->
						<article>
							<!-- <span  style="background-image: url('https://aiisc.ai/defactify/img/factify_logo_nav.png');" ></span> -->


							<div class="content">
								<!-- <h3>FACTIFY 2</h3> -->
								<img src="./images/text_detect_shared_task.png" alt="" srcset="">
								<p>Counter Turing Test : Text - Please visit <a href="./ai_gen_txt_detection.html" target="_blank"
										rel="noopener noreferrer">this link</a> for details.</p>
							</div>



						</article>
						<article>
							<!-- <span  style="background-image: url('https://aiisc.ai/defactify/img/factify_logo_nav.png');" ></span> -->


							<div class="content">
								<!-- <h3>FACTIFY 2</h3> -->
								<img src="./images/img_detect_shared_task.png"  alt="" srcset="">
								<p>Counter Turing Test : Images - Please visit <a href="./ai_gen_img_detection.html" target="_blank"
										rel="noopener noreferrer">this link</a> for details.</p>
							</div>



						</article>
						</article>
					</div>
					<div class="imp-dates">	
						<div class="time-lines">
							<h3>Counter Turing Test : Text</h3>
							<h4>Shared Task Important Dates:</h4>
							<ul>
								<li><strong>31 October 2024</strong>: Release of the training set.</li>
								<li><strong>10 November 2024</strong>: Release of the test set.</li>
								<li><strong>2 December 2024</strong>: Release of the <b>Updated</b> test set.</li>
								<li><strong><s>30 November</s> 7 December 2024</strong>: Deadline for submitting the final results.</li>
								<li><strong>12 December 2024</strong>: Announcement of the results.</li>
								<li><strong>05 January 2025</strong>: System paper submission deadline (All teams are invited to submit a paper).</li>
								<li><strong>20 January 2025</strong>: Notification of system papers.</li>
								<li><strong>25 January 2025</strong>: Camera-ready submission.</li>
							</ul>
							
						</div>
						<div class="time-lines">
							<h3>Counter Turing Test : Image</h3>
							<h4>Shared Task Important Dates:</h4>
							<ul>
								<li><strong>22 October 2024</strong>: Release of the training set.</li>
								<li><strong>10 November 2024</strong>: Release of the test set.</li>
								<li><strong>2 December 2024</strong>: Release of the <b>Updated</b> test set.</li>
								<li><strong><s>30 November</s> 7 December 2024</strong>: Deadline for submitting the final results.</li>
								<li><strong>12 December 2024</strong>: Announcement of the results.</li>
								<li><strong>05 January 2025</strong>: System paper submission deadline (All teams are invited to submit a paper).</li>
								<li><strong>20 January 2025</strong>: Notification of system papers.</li>
								<li><strong>25 January 2025</strong>: Camera-ready submission.</li>
							</ul>
							
						</div>
					</div>

				</section>

				<section class="accepted_section to_be_soon">
					<header class="major" id="accepted">
						<h2>Accepted Papers</h2>
					</header>
					<h4>To be announced</h4>
				</section>

				<section class="invited_section to_be_soon">
					<header class="major" id="invited">
						<h2>Invited Talks</h2>

					</header>
					<div>
						<h4>To be announced</h4>
					</div>
				</section>


				<!-- <section>
					<header class="major" id="invited">
					<h2>Invited Talks</h2>
					</header>
					<div style="display: flex;flex-direction:column;gap:30px;">
							
							
						<div style="display: flex;justify-content:space-evenly;text-align: justify;">
								<div style="text-align: center;flex: 1;">
									<img src="https://andreasvlachos.github.io//assets/img/prof_pic.jpg" class="organizer-images" alt="" />
									<h4>Dr. Andreas Vlachos</h4>
									<h4>Department of Computer Science and Technology <br> at the University of Cambridge</h4>
								</div>
								<div>
									<strong>NLP and ML Professor at University of Cambridge.</strong>
								<br>
								<strong>Creator of FEVER Dataset.</strong>
								<br>
								<strong>Organizer of Fake News Challenge.</strong>

								</div>
								
							</div>
							<hr>
							<div style="display: flex;justify-content:space-evenly;text-align: justify;">
								<div style="text-align: center;flex: 1;">
									
									<img src="https://scholar.googleusercontent.com/citations?view_op=medium_photo&user=DfXsKZ4AAAAJ&citpid=3" class="organizer-images" alt="">

										<h4>Dr. Preslav Nakov</h4>
									<h4>Mohamed bin Zayed University of Artificial Intelligence <br> Masdar City, Abu Dhabi</h4>
									</div>
									
								
								<div>	
									<strong>Computer Scientist working on NLP.</strong> <br>
								<strong>Organizer of NLP for Internet Freedom (NLP4IF).</strong> <br>
								<strong>Organizer of OffensEval Task</strong>

								</div>
							
								
					</div>
							
					

					</div>

				</section> -->

				<section id="organizing_committee_chairs"> </section>

				<section class="organizers" id = "web-chair"></section>
					
	
				<section class="organizers" id = "organizers"></section>
	
				<!-- <section class="organizers" id = "organizers">
					<h2>Web Chair</h2>
					<div class="card-container">
						<div class="card">
							<img src="./images/Rajarshi.jpg" alt="Rajarshi Roy" class="organizer-image">
							<h4>Rajarshi Roy</h4>
							<p>Kalyani Government Engineering College</p>
							<div class="links">
								<a href="https://www.linkedin.com/in/rajarshi-roy-learner/" target="_blank">LinkedIn</a>
								<a href="https://rajarshi12321.github.io/rajarshi_portfolio/" target="_blank">Portfolio</a>
							</div>
						</div>
			
					</div>
				
				</section>
				 -->
				
	
		<section id = "contacts"></section>
			  
		  <!-- Sidebar -->
		
		<div id="sidebar"> 
<div class="inner">
  <nav id="menu">
    <header class="major">
      <h2>Menu</h2>
    </header>
    <ul>
      <li><a href="#about">ABOUT CT2: AI-Generated Text Detection</a></li>
      <li><a href="#important">Important Dates</a></li>
      <li><a href="#chairs">ORGANIZING COMMITTEE CHAIRS</a></li>
      <li><a href="#web-chair">Web Chair</a></li>
      <li><a href="#organizers">ASSOCIATE ORGANIZERS</a></li>
      <li><a href="#contact">CONTACT US</a></li>
    </ul>
    <br />
    <br />
    <a href="/" style="font-size: 20px"> Defactify Workshop </a>
  </nav>
</div>
</div>
			
		<!-- Scripts -->
		 
		<script src="base.js"></script>
	
		<script src="assets/js/jquery.min.js"></script>
		<script src="assets/js/browser.min.js"></script>
		<script src="assets/js/breakpoints.min.js"></script>
		<script src="assets/js/util.js"></script>
		<script src="assets/js/main.js"></script>
	  </body>
</html>